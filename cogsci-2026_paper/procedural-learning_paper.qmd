---
title: "Procedural Learning with Graded Entropy"
format:
  pdf:
    documentclass: article
    classoption: [10pt,letterpaper]
    pdf-engine: pdflatex
    template-partials:
      - before-body.tex
    include-in-header:
      text: |
        \usepackage{cogsci}
        \usepackage{pslatex}
        \hyphenpenalty=10000
        \exhyphenpenalty=10000
    keep-tex: true
    cite-method: natbib
    natbiboptions: [numbers]
bibliography: CogSci_Template.bib
editor: source
---
```{r}
#| label: Load R libraries
#| echo: false
#| message: false

library(here)
library(osfr)
library(dplyr)
library(tidyr)
library(tidyverse)
library(zoo)
library(jsonlite)
library(clipr)
library(reticulate)
library(lmerTest) # show p value in lmer

np <- import("numpy")
```

# Abstract
::: {.abstract}
Your abstract text here. The abstract should be one paragraph. Following the abstract should be keywords.

**Keywords:** procedural learning, implicit learning, statistical learning
:::

# Introduction

Your introduction text here. You can cite references using `@NewellSimon1972a` or `[@ChalnickBillman1988a]`.

# Method

## Participants
```{r}
#| label: Demographic data
#| include: false
#| echo: false

df.demographics <- list.files(here("demographic-data/"), pattern = "*.csv", full.names=TRUE) %>%
  lapply(function(f) {
    matrix_size <- gsub('.*_(\\dx\\d)\\.csv', '\\1', basename(f))
    read.csv(f) %>%
      mutate(Matrix.size = matrix_size)
  }) %>%
  bind_rows() %>%
  filter(Status=="APPROVED")

overall_N <- nrow(df.demographics)
overall_mean_age <- mean(as.numeric(df.demographics$Age), na.rm=TRUE)
overall_median_age <- median(as.numeric(df.demographics$Age), na.rm=TRUE)
overall_sd_age <- sd(as.numeric(df.demographics$Age), na.rm=TRUE)
overall_age_range <- range(as.numeric(df.demographics$Age), na.rm=TRUE)

N_nationalities <- length(unique(df.demographics$Nationality))
N_languages <- length(unique(df.demographics$Language))

# Gender distribution
gender_counts <- table(df.demographics$Sex)
n_female <- gender_counts["Female"]
n_male <- gender_counts["Male"]
n_other <- sum(gender_counts[!names(gender_counts) %in% c("Female", "Male")], na.rm=TRUE)

df.demographics.group_summary <- df.demographics %>%
  group_by(Matrix.size) %>%
  summarise(N = n(),
            mean_age = mean(as.numeric(Age), na.rm=TRUE),
            sd_age = sd(as.numeric(Age), na.rm=TRUE),
            min_age = min(as.numeric(Age), na.rm=TRUE),
            max_age = max(as.numeric(Age), na.rm=TRUE))

group_N <- first(df.demographics.group_summary$N)
N_5x5 <- df.demographics.group_summary %>%
  filter(Matrix.size=="5x5") %>%
  pull(N)
```

We recruited `r overall_N` participants (`r n_female` female, `r n_male` male) to complete a web-based experiment using the online crowd-sourcing platform Prolific, screening for participants with an approval rating above 95% from previous studies and limiting participation to be on desktop or laptop computers. Participants ranged in age from `r overall_age_range[1]` to `r overall_age_range[2]` years ($\mu$=`r round(overall_mean_age, 1)`, $\sigma$=`r round(overall_sd_age, 1)`), representing `r N_nationalities` nationalities and `r N_languages` primary languages. Participants were compensated at $12.00 per hour, with median completion time varying by condition (~20-40 minutes). All participants provided informed consent prior to the experiment. The study was approved by the Institutional Review Board at the MGH Institute of Health Professions.

## Probabilistic Serial Reaction Time Task
```{r}
#| label: Experiment configs that stay constant across participants
#| echo: false
#| include: false

EXPERIMENT_CONFIG <- list(
  osf_id_4x4 = "Emfhw",
  osf_id_5x5 = "Fraxt",
  osf_id_6x6 = "jx48y",
  osf_id_7x7 = "92jq7",
  osf_id_8x8 = "Tx3h7",
  key_mapping_4pos = c("d","f","j","k"),
  key_mapping_5pos = c("s","d","f","j","k"),
  key_mapping_6pos = c("s","d","f","j","k","l"),
  key_mapping_7pos = c("a","s","d","f","j","k","l"),
  key_mapping_8pos = c("a","s","d","f","j","k","l",";"),
  n_blocks = 20,
  rsi = 120,
  error_feedback_duration = 200,
  error_tone_duration = 100,
  correct_feedback_duration = 200,
  estimated_trial_duration = 500,
  accuracy_threshold = 0.65,
	rt_threshold = 1000
)
```
Like other serial reaction time task designs, our experiment tasks participants to respond to a visual stimulus that appears in one of several evenly-spaced positions on screen as quickly and accurately as possible by pressing a corresponding key on the keyboard. In our implementation, this visual stimulus is a mole garbed in a bright red bib and matching sunglasses (@fig-example-trial-screen); and a schematic of each position-to-keyboard mapping for each condition is shown in (Table). Participants were evenly divided into 5 groups of `r group_N` per condition, with the conditions differing in the number of positions (4, 5, 6, 7, 8) the mole can appear in.

![An example trial screen in the 8-position condition of the experiment]("../assets/example-trial-screen.png"){#fig-example-trial-screen width=100%}

A participant is first given a text-based tutorial accompanied by an animated demonstration on which key to press in response to each position, then instructed to work through a set of practice trials where each position is visited twice in random order. After the practice section, the participant moves on to complete `r EXPERIMENT_CONFIG$n_blocks` blocks of trials, each separated with a self-paced break. Each block consists of trials 10x the number of positions in the participant's assigned condition. This design choice results in longer blocks for conditions with more positions, but ensures each position is visited an equal number of times on average across conditions. In both practice and main trials, participants are given feedback on correctness via a pop-up short message (a checkmark vs. "Try again!" + an error tone), and allowed to retry each failed trial until they respond correctly. Following standard SRTT protocol, there is also a 120ms response-stimulus interval (RSI) between trials [CITE]. We find during piloting that allowing retries, combined with the `r EXPERIMENT_CONFIG$rsi`ms RSI, prevents participants from making compensatory errors, where they unintentionally press the wrong key in the next trial in an attempt to correct their current trial. We record response time, keyboard response and correctness for each trial. After each block, participants are given adaptive feedback based on their accuracy and speed. At the end of the experiment, participants complete a brief questionnaire probing their explicit awareness of any patterns in the mole's appearances (Table).

In addition to our dapper mole, a number of design choices were made to facilitate participant understanding and engagement. During the practice phase, each position on screen is labelled with its corresponding key character (e.g. "A", "S", "D") to help familiarize participants with the keyboard mappings. These key labels disappear in the main trials to prevent explicitly encoding of the sequence of positions via their character labels, but reappear during retry of failed trials. To make the correspondence between the positions on screen and keyboard keys as automatic and intuitive as possible, we chose to use conventional QWERTY-based finger layouts for the key mappings across conditions (Table). We found during piloting that while this decision helped reduce cognitive load from learning novel finger placements, the larger gap between keys "F" and "J" on the keyboard introduced a discrepancy between the evenly-spaced on-screen positions and the unevenly spaced keyboard keys. This made participants more prone to making errors in the positions towards the middle of the screen compared to those on the outer edges, especially when number of positions increases [TODO: maybe run stats on pilot to find this effect]; and was not mitigated by shifting either hand's placement to close the extra gap, because the positions were still corresponding half to one hand and half to the other. After further piloting testing different visual aids, we settled on adding two hands visually to the bottom of the screen, each finger aligned with its target position (Figure). We received verbal feedback that this visual aid helped participants better map the spatial layout of the on-screen positions to their corresponding keys. Lastly, the visual design of the "positions" on screen mimicked blank 3D keyboard keys that light up in pink when the mole appears on top, and look visibly "pressed down" when the participant presses the corresponding keyboard key. This design choice links the on-screen positions diegetically to the physical keyboard keys to maximally reduce mental distance between the two. This is important to enforce as much learning via implicit motor memory as possible, rather than via visual-spatial memory of the on-screen positions.

## Transition Matrices
```{r}
#| label: Original transition matrices
#| echo: false
#| include: false

# Shannon entropy (bits) of a single probability vector (skip zeros)
row_entropy <- function(prob_vec) {
  p <- prob_vec[prob_vec > 0]
  -sum(p * log2(p))
}

# Calculate positional entropy for each row in a transition matrix
positional_entropy <- function(mat) {
  apply(mat, MARGIN=1, row_entropy)
}

transition_matrix_4x4 <- matrix(unlist(np$load(here("assets/transition-matrices/matrix_4x4.npy"))$tolist()), nrow=4, byrow=TRUE)
transition_matrix_5x5 <- matrix(unlist(np$load(here("assets/transition-matrices/matrix_5x5.npy"))$tolist()), nrow=5, byrow=TRUE)
transition_matrix_6x6 <- matrix(unlist(np$load(here("assets/transition-matrices/matrix_6x6.npy"))$tolist()), nrow=6, byrow=TRUE)
transition_matrix_7x7 <- matrix(unlist(np$load(here("assets/transition-matrices/matrix_7x7.npy"))$tolist()), nrow=7, byrow=TRUE)
transition_matrix_8x8 <- matrix(unlist(np$load(here("assets/transition-matrices/matrix_8x8.npy"))$tolist()), nrow=8, byrow=TRUE)
all_original_matrices <- list(
  "4x4" = transition_matrix_4x4,
  "5x5" = transition_matrix_5x5,
  "6x6" = transition_matrix_6x6,
  "7x7" = transition_matrix_7x7,
  "8x8" = transition_matrix_8x8
)

all_positional_entropies <- lapply(all_original_matrices, positional_entropy)
all_positional_entropies_df <- lapply(names(all_positional_entropies), function(size) {
  data.frame(
    Matrix.size = size,
    Position = 1:length(all_positional_entropies[[size]]),
    Entropy = all_positional_entropies[[size]]
  )
}) %>%
  bind_rows()

pos_1_entropy <- all_positional_entropies_df %>%
  group_by(Matrix.size) %>%
  filter(Position==1) %>%
  ungroup() %>%
  summarize(range=range(Entropy), mean=mean(Entropy), sd=sd(Entropy))

pos_n_entropy <- all_positional_entropies_df %>%
  group_by(Matrix.size) %>%
  filter(Position==max(Position)) %>%
  ungroup() %>%
  summarize(range=range(Entropy), mean=mean(Entropy), sd=sd(Entropy))

entropy_gradient_summary <- all_positional_entropies_df %>%
  group_by(Matrix.size) %>%
  summarize(entropy_diffs = list(diff(Entropy))) %>%
  ungroup() %>%
  summarize(
    range_diff = list(range(unlist(entropy_diffs))),
    mean_diff = mean(unlist(entropy_diffs)),
    sd_diff = sd(unlist(entropy_diffs))
  )
```

Our experiment deviates from other serial reaction time tasks in how the sequence of positions and its probabilistic structure is constructed. In each run of the experiment, we use a first-order Markov process to generate the sequence of positions the mole appears in. This process is defined by a transition matrix, where each entry in the matrix defines the probability of transitioning from one position to another. We designed five different transition matrices of sizes 4x4, 5x5, 6x6, 7x7, and 8x8 respectively corresponding to the five conditions in our experiment. These "original" matrices were constructed to have graded and increasing levels of entropy across rows, such that position 1 has lowest entropy-having the most predictable next-position-transitions, followed by the second, with the last position, position n, having highest entropy. For example, in the 4x4 matrix, position 1 has a high probability (~`r round(transition_matrix_4x4[1,2], 2)`) of transitioning to position 2, a low probability (~`r round(transition_matrix_4x4[1,1], 2)`) of transitioning to position 1, and never transitions to position 3 or 4; while position 4 has a more uniform distribution of transition probabilities to all other positions (to 1: ~(`r round(transition_matrix_4x4[4,1], 2)`), to 2: ~(`r round(transition_matrix_4x4[4,2], 2)`), to 3: ~(`r round(transition_matrix_4x4[4,3], 2)`), to 4: ~(`r round(transition_matrix_4x4[4,4], 2)`)). This gives rise to a gradient of entropy values across the positions, which results in a richer, more varied distributed statistical structure underlying the sequence of positions the mole appears in, allowing us to investigate how the procedural learning system differentially picks up varying levels of predictability in a given statistical structure.

Several design criteria/constraints were imposed on the construction of these original transition matrices. First, these matrices had to be doubly stochastic to ensure uniform visitation to each position over time, preventing confounding effects from position frequency on learning. Second, self-transitions (e.g. position 1 to position 1) should have near-zero probabilities to reduce data loss, as data from repeated trials have been historically thrown out from analysis in serial reaction time tasks to prevent confounding motor effects from repeating the same keypress [CITE]. Third, the graded entropy levels across the positions should translate to graded probabilities across bigrams as well, as having more fine-grained, distributed levels of transition probabilities is our experiment's key distinction from other SRTT tasks, such as the ASRT paradigm which only has 2 levels of trigram probability. Fourth, the increase in entropy across positions (i.e. rows) should be significant between one another and as linear as possible to ensure smooth a smooth gradient with meaningfully distinct levels in predictability across positions.

Strictly satisfying all these constraints at once turned out to be not only non-trivial, but mathematically impossible for our range of n_positions (i.e. matrix sizes), so we wrote an optimization algorithm that explores the candidate space for each matrix size, treating these constraints as soft penalties to find a global minimum of the total constraint violation, balancing trade-offs among the competing constraints.

The five original matrices we constructed using this algorithm had these properties: 1) near fully doubly stochastic—all row and column sums sum to 1 (±0.0001) [TODO: consider not hardcoding]; 2) approach a uniform stationary distribution after 7 timesteps [TODO: consider not hardcoding] where the stationary visitation for each state (position) are within 0.001 of each other; 3) had a graded entropy structure across states—each matrix had a positional entropy range of `r round(pos_1_entropy$range[1], 3)`-`r round(pos_1_entropy$range[2], 3)` bits for position 1 ($\mu$=`r round(pos_1_entropy$mean[1], 3)`, $\sigma$=`r round(pos_1_entropy$sd[1], 3)`), and `r round(pos_n_entropy$range[1], 3)`-`r round(pos_n_entropy$range[2], 3)` bits for position n ($\mu$=`r round(pos_n_entropy$mean[1], 3)`, $\sigma$=`r round(pos_n_entropy$sd[1], 3)`). Within a matrix each position increases in entropy from the previous by `r round(entropy_gradient_summary$range_diff[[1]][1], 3)`-`r round(entropy_gradient_summary$range_diff[[1]][2], 3)` bits ($\mu$=`r round(entropy_gradient_summary$mean_diff[1], 3)`, $\sigma$=`r round(entropy_gradient_summary$sd_diff[1], 3)`); and 4) avoided self loops as much as possible—all of the matrices had <0.08 [TODO: consider not hardcoding] probabilities in the left diagonal up until the last two positions. Within each matrix size condition, all participants experience the same underlying entropy gradient across positions, but the mapping between screen positions and entropy levels is randomized through a double permutation procedure that shuffles the original matrix (of that size) using the same random permutation. This preserves the statistical properties of the original matrix—transition probabilities and entropy values—but decouples entropy levels from specific screen positions. The position sequence for each participant is subsequently generated using their individual shuffled transition matrix, so the sequence each participant experiences is different both within and between matrix size conditions.

## Hypotheses
> **H0. Procedural learning effect.** We predict participants to show implicit learning of the statistical structure across blocks, evidenced by a) decrease in response time across blocks and b) increase in accuracy across blocks.

> **H1a. Surprisal effect.** In each experiment run, positions differ in how many next-positions are possible and how evenly distributed the transition probabilities are among them, which also means different next-position/bigram combinations for a given first position yield different levels of predictability and thus surprisal to the participant. We predict that participants will respond faster and more accurately on bigram transitions that are higher probability.

> **H1b. Previous positional entropy effect.** In each experiment run, positions differ in their transition entropy---how many next-positions are possible and how evenly distributed the transition probabilities are among them. We predict that this influences how easily participants can predict the next position based on a given position, so participants will respond a) faster and b) more accurately on trials where the previous trial has lower entropy.

> **H1c. Interaction effect between surprisal and previous positional entropy.** The effect of surprisal on rt will be modulated by entropy, such that surprisal effects are stronger at low-entropy (predictable) positions and weaker at high-entropy (uncertain) positions. This is because entropy determines prediction confidence. In low-entropy contexts, participants form strong, specific expectations, making prediction errors (high surprisal) more costly. In high-entropy contexts, predictions are weaker and more distributed, attenuating surprisal effects.

> **H2a. Prediction error reflecting surprisal effect.** We predict that as participants implicitly learn the underlying statistical distribution, the mistakes they make reflect this learning, i.e. across blocks, the mistakes they make will be a) increasingly on low probability bigram transitions and b) the false transitions they make will increasingly be higher probability bigram transitions...

> **H2b. Prediction error reflecting entropy effect.** ...and they will also be increasingly limited to higher previous positional entropy trials.

> **H3. Moderation from number of positions.** We predict that the more positions there are to handle, the more difficult it is to learn the underlying statistical distribution, so participants with a larger number of positions will have a gentler learning slope, higher mean/median RT and also show worse performances/take more blocks to reach the same level of performance (in terms of both RT and accuracy) on the effects predicted in H1 (and H2).

*Note: Matrix size is confounded with entropy range, so effects may reflect entropy distribution rather than number of positions per se.*

# Statistical Analysis
```{r}
#| label: Retrieve data from OSF
#| echo: false
#| include: false
#| cache: true

files_4x4 <- osf_retrieve_node(EXPERIMENT_CONFIG$osf_id_4x4) %>%
  osf_ls_files(n_max = Inf) %>%
  osf_download(path = here("data/4x4-data"), conflicts="skip")

files_5x5 <- osf_retrieve_node(EXPERIMENT_CONFIG$osf_id_5x5) %>%
  osf_ls_files(n_max = Inf) %>%
  osf_download(path = here("data/5x5-data"), conflicts="skip")

files_6x6 <- osf_retrieve_node(EXPERIMENT_CONFIG$osf_id_6x6) %>%
  osf_ls_files(n_max = Inf) %>%
  osf_download(path = here("data/6x6-data"), conflicts="skip")

files_7x7 <- osf_retrieve_node(EXPERIMENT_CONFIG$osf_id_7x7) %>%
  osf_ls_files(n_max = Inf) %>%
  osf_download(path = here("data/7x7-data"), conflicts="skip")

files_8x8 <- osf_retrieve_node(EXPERIMENT_CONFIG$osf_id_8x8) %>%
  osf_ls_files(n_max = Inf) %>%
  osf_download(path = here("data/8x8-data"), conflicts="skip")
```

```{r}
#| label: Bind all data together
#| echo: false
#| include: false
#| cache: true
df.raw <- list.files(here("data/"), pattern = "*.csv", full.names=TRUE, recursive=TRUE) %>%
  .[!grepl("pilot-data", .)] %>%
  lapply(read.csv) %>%
  bind_rows()
```

```{r}
#| label: Filter out unnecessary columns
#| echo: false
#| include: false
#| cache: true
df <- subset(df.raw, select=c(trial_index, subject_id, matrix_size, trials_per_block, total_trials, practice_trials, transition_matrix, conditional_entropies, phase, block, experiment_trial_type, trial_in_block, overall_trial, position, correct_key, response, correct, rt, conditional_entropy, surprisal, questionnaire_item))
```

```{r}
#| label: Clean up data formatting
#| echo: false
#| include: false
#| cache: true

# Convert NA values
df <- df %>%
  mutate(across(where(is.character), ~{
    x <- .
    x[x %in% c("NA", "na", "null", "NULL", "")] <- NA
    x
  }))

# Convert boolean values
df <- df %>%
  mutate(across(where(is.character), ~ {
    x <- tolower(.)
    if (all(x %in% c("true", "false", NA))) {
      as.logical(x)
    } else {
      .
    }
  }))

# Convert numeric values
df <- df %>%
  mutate(across(where(is.character), ~ {
    x <- .
    is_num <- suppressWarnings(!is.na(as.numeric(x)) | is.na(x))
    if (all(is_num)) as.numeric(x) else x
  }))

# Fill down overall_trial, trial_in_block and block
df <- df %>%
 group_by(subject_id) %>%
    arrange(subject_id, row_number()) %>%
    mutate(
      overall_trial = if_else(
        experiment_trial_type %in% c("feedback", "rsi"),
        zoo::na.locf(overall_trial, na.rm = FALSE),  # Fill down
        overall_trial  # Keep as-is
      ),
      trial_in_block = if_else(
        experiment_trial_type %in% c("feedback", "rsi"),
        zoo::na.locf(trial_in_block, na.rm = FALSE), 
        trial_in_block
      ),
      block = if_else(
        experiment_trial_type %in% c("feedback", "rsi"),
        zoo::na.locf(block, na.rm = FALSE), 
        block
      )
    ) %>%
    ungroup()
```

```{r}
#| label: Sanity check for unique subject_ids, matrix size, total number of trials, practice trials, transition matrices, conditional entropies and sequences across subjects and conditions
#| echo: false
#| include: false
#| cache: true

unique_subjects <- unique(df$subject_id)

df %>%
  group_by(matrix_size) %>%
  summarize(
    n_subjects = n_distinct(subject_id),
    total_trials = unique(total_trials),
    practice_trials = unique(practice_trials),
    transition_matrix = list(unique(transition_matrix)),
    conditional_entropies = list(unique(conditional_entropies)),
    sequences = list(unique(position))
  )
```

```{r}
#| label: Separate practice, main and questionnaire sections
#| echo: false
#| include: false
#| cache: true

df.practice <- df[df$phase=="practice", ]
df.questionnaire <- df[df$phase=="questionnaire", ]
df <- df[df$phase=="main", ]
```

```{r}
#| label: exclude-subjects
#| echo: false
#| include: false
#| cache: true

# Exclude subjects that
# 1. Made too many mistakes (more than 15%)
# 2. Have too long response time (look at mean, median and spread)
# -> exclude if too slow--the subject's median_rt > 1000ms
# -> or if too noisy--more than 20% of their trials are 3*mad higher than the subject's median_rt

accuracy_excluded_subjects <- df %>%
  filter(matrix_size==8) %>%
  filter(!is.na(correct)) %>%
  group_by(subject_id) %>%
  summarize(error_rate = mean(!correct)) %>%
  filter(error_rate > 0.15) %>%
  pull(subject_id)

rt_excluded_subjects <- df %>%
  filter(
    (experiment_trial_type == "stimulus" | experiment_trial_type == "retry")
    & !is.na(rt)) %>% 
  group_by(subject_id) %>%
  summarize(
    median_rt = median(rt),
    outlier_prop = mean(rt > median(rt) + 3*mad(rt))
  ) %>%
  filter(median_rt > 1000 | outlier_prop > 0.2) %>%
  pull(subject_id)

df <- df %>%
  filter(!subject_id %in% accuracy_excluded_subjects & !subject_id %in% rt_excluded_subjects)
```

```{r}
#| label: Make a new column for log(rt)
#| echo: false
#| include: false
#| cache: true

df <- df %>%
  mutate(log_rt=log(rt))
```

## Variables and Exclusion Criteria
The main independent variables are surprisal and previous positional entropy. Surprisal is defined as the negative log probability of the actual next-position given the current position [TODO: math], derived from the transition matrix used to generate the sequence for that participant. Previous positional entropy is defined as the Shannon entropy of the transition probabilities from the previous position, also derived from the transition matrix [TODO: math]. Both surprisal and previous positional entropy are mean-centered within each matrix size condition to facilitate interpretation of main effects and interactions in subsequent models. We also create a binary variable indicating whether the current position is a repetition of the previous position (i.e. self-transition). This variable is included as a covariate in subsequent models to control for potential motor effects from repeating the same keypress.

The main dependent variables are response time (RT) and accuracy (proportion of correct responses) on non-practice/main trials. Incorrect trials, trials with RT >1000ms RT, and trials with RTs greater than 3 median absolute deviations above the participant's median RT (outliers) are excluded. On the participant level, participants with overall accuracy below 85%, median RT >1000ms, or with outliers making up more than 30% of total trials are excluded from analysis. We also discard data from the first trial of each block to account for blocks being implicitly treated as "restarts" and not following an existing probability distribution by participants. RTs are log-transformed to reduce skewness.

## Modeling Approach
We use linear mixed effects regression (LMER) to model log-transformed RTs and generalized linear mixed effects regression (GLMER) with a binomial link function to model accuracy. Models are fit using the `lmerTest` package in R. We first test for the learning effect across blocks (H0), then examine the effects of surprisal and previous positional entropy (H1 & H2) in the final block, pruning effects where applicable to narrow in on the best-fitting effects structure before analyzing learning trajectories across blocks, and finally test for moderation by number of positions/matrix size(H3).

Models are initially fit with the maximal random effects structure supported by the design: random intercepts for participant and position, and random slopes for surprisal, previous positional entropy, their interaction, and position repetition by participant. Where maximal models fail to converge, we use bounded linear mixed models (`blmer`/`bglmer`) as a first remedy. If singularity persists, we iteratively simplify the random effects structure, removing random slopes one at a time and retaining the most complex structure that converges without singularity. Among converging models, we select the one with the lowest AIC.

For H1 and H2, we first establish the fixed effects structure using only the final block of trials, then extend to learning trajectories across blocks. Starting from a base model including surprisal, previous positional entropy, their interaction, and repetition as fixed effects (with the selected random effects structure), we use AIC-based model comparison to prune fixed effects. We first test whether repetition is significant by comparing the base model against one in which it is removed; if removing it does not increase AIC, we drop it from the base model. We then test whether the interaction term between surprisal and previous positional entropy is significant by comparing the current base model against one in which the interaction term is removed. If the interaction is not significant, we test each main effect individually by comparing models that omit surprisal or previous positional entropy as main effects. An effect is retained if removing it increases AIC.

```{r}
#| label: Make a new column for previous position entropy
#| echo: false
#| include: false
#| cache: true

df <- df %>%
  group_by(subject_id, block) %>%
  mutate(previous_entropy=lag(conditional_entropy, 1))
```

```{r}
#| label: Make a new column for prev_entropy_c
#| echo: false
#| include: false
#| cache: true

df <- df %>%
  group_by(matrix_size) %>%
  mutate(prev_entropy_c=previous_entropy-mean(previous_entropy, na.rm=TRUE))
```

```{r}
#| label: Make a new column for surprisal_c
#| echo: false
#| include: false
#| cache: true

df <- df %>%
  group_by(matrix_size) %>%
  mutate(surprisal_c=surprisal-mean(surprisal, na.rm=TRUE))
```

```{r}
#| label: Make a new column for is_repetition
#| echo: false
#| include: false
#| cache: true

df <- df %>%
  mutate(is_repetition=(position==lag(position,1)))
```

```{r}
#| label: Remove first trial of each block
#| echo: false
#| include: false
#| cache: true

df <- df %>%
  group_by(block, subject_id) %>%
  slice(2:n())
```

```{r}
#| label: Make subset of df with only correct trials
#| echo: false
#| include: false
#| cache: true

df.correct <- df %>%
  filter(correct)
```


## H0. Learning Effect

# Results

## H0

## H1

## H2

## H3

# Discussion

# References

::: {#refs}
:::

