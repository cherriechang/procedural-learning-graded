---
title: "procedural-learning-graded-entropy-data-analysis"
author: "Cherrie Chang"
format: html
editor: visual
---

# Data Analysis for Procedural Learning Graded Entropy Design Experiment

## Libraries

```{r}
#| label: Load R libraries
#| echo: false
#| message: false

library(osfr)
library(dplyr)
library(tidyr)
library(tidyverse)
library(zoo)
library(jsonlite)
library(clipr)
library(lme4)
library(lmerTest) # show p value in lmer
```

## Global Variables

```{r}
#| label: Experiment configs that stay constant across participants
#| echo: false
#| include: false

EXPERIMENT_CONFIG <- list(
  datapipe_id_4x4 = "lpRUgvFf5pm4",
  osf_id_4x4 = "5zn6u",
  key_mapping_4pos = c("d","f","j","k"),
  key_mapping_5pos = c("s","d","f","j","k"),
  key_mapping_6pos = c("s","d","f","j","k","l"),
  key_mapping_7pos = c("a","s","d","f","j","k","l"),
  key_mapping_8pos = c("a","s","d","f","j","k","l",";"),
  n_blocks = 20,
  rsi = 120,
  error_feedback_duration = 200,
  error_tone_duration = 100,
  correct_feedback_duration = 200,
  estimated_trial_duration = 500,
  accuracy_threshold = 0.65,
	rt_threshold = 1000
)
```

## Data

### Download Data

```{r}
#| label: Retrieve pilot data from OSF
#| echo: false
#| include: false

osf_auth(token = "HoZsxwf02iQ5JQCs6YuMaIWQWLLIvhKNZxJjdLClW1ZbyRZNPpPuBzAcuLymvkfQM1g8MG")

files <- osf_retrieve_node("Fraxt") %>%
  osf_ls_files(n_max = Inf) %>%
  osf_download(path = "data/4x4-data", conflicts="skip")
```

```{r}
#| label: Bind all data together
#| echo: false
#| include: false

df.raw <- list.files("data/4x4-data", full.names = TRUE) %>%
  lapply(read.csv, colClasses="character") %>%
  bind_rows()
```

### Data Cleanup

```{r}
#| label: Filter out unnecessary columns
#| echo: false
#| include: false
df <- subset(df.raw, select=c(trial_index, subject_id, matrix_size, transition_matrix, conditional_entropies, trials_per_block, total_trials, practice_trials, phase, block, experiment_trial_type, trial_in_block, overall_trial, position, correct_key, response, correct, rt, conditional_entropy, surprisal, questionnaire_item)) %>%
  mutate(rt = as.numeric(rt))
```

```{r}
#| label: Clean up data formatting
#| echo: false
#| include: false

# Convert NA values
df <- df %>%
  mutate(across(where(is.character), ~{
    x <- .
    x[x %in% c("NA", "na", "null", "NULL", "")] <- NA
    x
  }))

# Convert boolean values
df <- df %>%
  mutate(across(where(is.character), ~ {
    x <- tolower(.)
    if (all(x %in% c("true", "false", NA))) {
      as.logical(x)
    } else {
      .
    }
  }))

# Convert numeric values
df <- df %>%
  mutate(across(where(is.character), ~ {
    x <- .
    is_num <- suppressWarnings(!is.na(as.numeric(x)) | is.na(x))
    if (all(is_num)) as.numeric(x) else x
  }))

df <- df %>%
  mutate(conditional_entropies = map(conditional_entropies, fromJSON)) %>%
  mutate(transition_matrix = map(transition_matrix, fromJSON))


# Fill down overall_trial, trial_in_block and block
df <- df %>%
 group_by(subject_id) %>%
    arrange(subject_id, row_number()) %>%
    mutate(
      overall_trial = if_else(
        experiment_trial_type %in% c("feedback", "rsi"),
        zoo::na.locf(overall_trial, na.rm = FALSE),  # Fill down
        overall_trial  # Keep as-is
      ),
      trial_in_block = if_else(
        experiment_trial_type %in% c("feedback", "rsi"),
        zoo::na.locf(trial_in_block, na.rm = FALSE), 
        trial_in_block
      ),
      block = if_else(
        experiment_trial_type %in% c("feedback", "rsi"),
        zoo::na.locf(block, na.rm = FALSE), 
        block
      )
    ) %>%
    ungroup()
```

```{r}
#| label: Separate practice, main and questionnaire sections 
#| echo: false
#| include: false

df.practice <- df[df$phase=="practice", ]
df.questionnaire <- df[df$phase=="questionnaire", ]
df <- df[df$phase=="main", ]
```

### Data Exclusions

<!-- TODO: can consider removing subjects that didn't go fullscreen and/or preload failed..? -->

<!-- TODO: used median absolute deviation instead of standard deviation for RT but not sure -->

```{r}
#| label: Exclude subjects that:
#| 1. Made too many mistakes (more than 15%)
#| 2. Have too long response time (look at mean, median and spread):
#| -> exclude if too slow: the subject's median_rt > 1000ms
#| -> or if too noisy: more than 20% of their trials are 3*mad higher than the subjct's median_rt
#| echo: false
#| include: false

accuracy_excluded_subjects <- df %>%
  filter(!is.na(correct)) %>%
  group_by(subject_id) %>%
  summarize(error_rate = mean(!correct)) %>%
  filter(error_rate > 0.10) %>%
  pull(subject_id)

rt_excluded_subjects <- df %>%
  filter(
    (experiment_trial_type == "stimulus" | experiment_trial_type == "retry")
    & !is.na(rt)) %>% 
  group_by(subject_id) %>%
  summarize(
    median_rt = median(rt),
    outlier_prop = mean(rt > median(rt) + 3*mad(rt))
  ) %>%
  filter(median_rt > 1000 | outlier_prop > 0.2) %>%
  pull(subject_id)

df <- df %>%
  filter(!subject_id %in% accuracy_excluded_subjects & !subject_id %in% rt_excluded_subjects)
```

```{r}
#| label: Filter df down to only stimulus, non-retry trials
#| echo: false
#| include: false

df <- df %>%
  filter(experiment_trial_type=="stimulus" & !is.na(rt))
```

```{r}
#| label: Make a new column for log(rt)
#| echo: false
#| include: false

df <- df %>%
  mutate(log_rt=log(rt))
```

```{r}
#| label: Make a new column for previous position entropy
#| echo: false
#| include: false

df <- df %>%
  group_by(subject_id, block) %>%
  mutate(previous_entropy=lag(conditional_entropy, 1))
```

```{r}
#| label: Make a new column for prev_entropy_c
#| echo: false
#| include: false

df <- df %>%
  group_by(matrix_size) %>%
  mutate(prev_entropy_c=previous_entropy-mean(previous_entropy, na.rm=TRUE))
```

```{r}
#| label: Make a new column for surprisal_c
#| echo: false
#| include: false

df <- df %>%
  group_by(matrix_size) %>%
  mutate(surprisal_c=surprisal-mean(surprisal, na.rm=TRUE))
```

```{r}
#| label: Make a new column for is_repetition
#| echo: false
#| include: false

df <- df %>%
  mutate(is_repetition=(position==lag(position,1)))
```

```{r}
#| label: Remove first trial of each block
#| echo: false
#| include: false

df <- df %>%
  group_by(block, subject_id) %>%
  slice(2:n())
```

```{r}
#| label: Make subset of df with only correct trials
#| echo: false
#| include: false

df.correct <- df %>%
  filter(correct)
```

## Stats!

### Power Analysis

### Descriptive stats

#### Overall

```{r}
#| label: N, total trials, mean, median overall
#| echo: false
#| include: false

# Within subjects
overall_within_subs_stats <- df %>%
  group_by(subject_id) %>%
  summarise(
    accuracy = mean(correct),
    mean_rt = mean(rt[correct]),
    median_rt = median(rt[correct]),
    sd_rt = sd(rt[correct]),
    n_correct_trials = sum(correct),
    n_trials = n(),
    .groups = "drop"
  )

# Across subjects
overall_across_subs_stats <- within_subs_stats %>%
  summarise(
    N = n(),
    mean_mean_rt = mean(mean_rt),        # Mean of means
    between_subs_sd_rt = sd(mean_rt),    # Between-subject SD
    median_median_rt = median(median_rt),# Median of medians
    mean_accuracy = mean(accuracy),
    sd_accuracy = sd(accuracy)
  )
```

#### By Block

```{r}
#| label: N, total trials, mean, median by block
#| echo: false
#| include: false

by_block_within_subs_stats <- df %>%
  group_by(subject_id, block) %>%
  summarise(
    accuracy = mean(correct),
    mean_rt = mean(rt[correct]),
    median_rt = median(rt[correct]),
    sd_rt = sd(rt[correct]),
    n_correct_trials = sum(correct),
    n_trials = n(),
    .groups = "drop"
  )

by_block_across_subs_stats <- by_block_within_subs_stats %>%
  group_by(block) %>%
  summarize(
    N = n(),
    mean_mean_rt = mean(mean_rt),        
    between_subs_sd_rt = sd(mean_rt),    
    median_median_rt = median(median_rt),
    mean_accuracy = mean(accuracy),
    sd_accuracy = sd(accuracy)
  )
```

#### By Matrix Size

```{r}
#| label: N, total trials, mean, median by matrix size
#| echo: false
#| include: false

by_matrix_size_within_subs_stats <- df %>%
  group_by(subject_id, matrix_size) %>%
  summarise(
    accuracy = mean(correct),
    mean_rt = mean(rt[correct]),
    median_rt = median(rt[correct]),
    sd_rt = sd(rt[correct]),
    n_correct_trials = sum(correct),
    n_trials = n(),
    .groups = "drop"
  )

by_matrix_size_across_subs_stats <- by_matrix_size_within_subs_stats %>%
  group_by(matrix_size) %>%
  summarize(
    N = n(),
    mean_mean_rt = mean(mean_rt),        
    between_subs_sd_rt = sd(mean_rt),    
    median_median_rt = median(median_rt),
    mean_accuracy = mean(accuracy),
    sd_accuracy = sd(accuracy)
  )
```

#### By Entropy Level

```{r}
#| label: N, total trials, mean, median by conditional entropy
#| echo: false
#| include: false

by_entropy_within_subs <- df %>%
  group_by(subject_id, entropy) %>%
  summarise(
    accuracy = mean(correct),
    mean_rt = mean(rt[correct]),
    median_rt = median(rt[correct]),
    sd_rt = sd(rt[correct]),
    n_correct_trials = sum(correct),
    n_trials = n(),
    .groups = "drop"
  ) 
  
by_entropy_across_subs <- df %>%
  group_by(entropy) %>%
  summarise(
    N = n(),
      mean_mean_rt = mean(mean_rt),        
      between_subs_sd_rt = sd(mean_rt),    
      median_median_rt = median(median_rt),
      mean_accuracy = mean(accuracy),
      sd_accuracy = sd(accuracy)
    )
  )
```

## H0. Learning Effect

```{r}
#| label: Learning effect lmer models
#| (filter for correct trials and group by matrix_size)
#| 
#| echo: true
#| include: true

data.m_h0 <- df %>%
  group_by(matrix_size) %>%
  filter(!is.infinite(log_rt))

data.m_h0.correct <- df.correct %>%
  group_by(matrix_size)

m_h0_rt <-
  lmer(-log_rt ~ block + is_repetition + (block | subject_id) + (1 | position),
       data=data.m_h0,
       REML=FALSE,
       control=lmerControl(optimizer="bobyqa")) # can change

m_h0_acc <-
  glmer(correct ~ block + is_repetition + (block | subject_id) + (1 | position),
       data=data.m_h0,
       family=binomial,
       control=glmerControl(optimizer="bobyqa")) # can change

summary(m_h0_rt)
summary(m_h0_acc)
```

## H1 & H2. Surprisal and previous position entropy effects

For H1 & H2, we analyze each block independently. First, we determine the effects structure by analyzing only the final block as follows: *(When the best-fit base model for surprisal and/or previous position entropy effects has been found, we can then examine learning trajectories by adding block as a continuous predictor)*

```{r}
#| label: Surprisal x previous position entropy lmer models
#| (filter for correct trials + final block and group by matrix_size)
#| 
#| echo: true
#| include: true

data.m_h1h2 <- df %>%
  filter(block==EXPERIMENT_CONFIG[["n_blocks"]]-1, !is.infinite(log_rt)) %>%
  group_by(matrix_size)

data.m_h1h2.correct <- df.correct %>%
  filter(block==EXPERIMENT_CONFIG[["n_blocks"]]-1) %>%
  group_by(matrix_size)

m_surprisal_x_entropy_rt <- 
  lmer(log_rt ~ surprisal_c * prev_entropy_c + is_repetition +
         (surprisal_c * prev_entropy_c + is_repetition | subject_id) +
         (1 | position),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="bobyqa")) # can change

m_surprisal_x_entropy_acc <-
  glmer(correct ~ surprisal_c * prev_entropy_c + is_repetition +
         (surprisal_c * prev_entropy_c + is_repetition | subject_id) +
         (1 | position),
       data=data.m_h1h2,
       family=binomial,
       control=glmerControl(optimizer="bobyqa")) # can change

summary(m_surprisal_x_entropy_rt)
summary(m_surprisal_x_entropy_acc)
```
solve singular fit: 

+ remove random slope until isSingular() is False
+ compare models AIC, and our design mainly focus on surperisal and entropy, final random slope without singular fit exclude interaction and is_repetition


```{r}
m_surprisal_x_entropy_rt_simple <- 
  lmer(log_rt ~ surprisal_c * prev_entropy_c + is_repetition +
         (surprisal_c + prev_entropy_c | subject_id) +
         (1 | position),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="bobyqa")) # can change

summary(m_surprisal_x_entropy_rt_simple)
isSingular(m_surprisal_x_entropy_rt_simple)

# AIC(m_surprisal_x_entropy_rt, m_surprisal_x_entropy_rt_simple)

fixef_comparison <- data.frame(
  Complex = fixef(m_surprisal_x_entropy_rt),
  Simple = fixef(m_surprisal_x_entropy_rt_simple),
  Diff_pct = 100 * abs(fixef(m_surprisal_x_entropy_rt) - fixef(m_surprisal_x_entropy_rt_simple)) / 
             abs(fixef(m_surprisal_x_entropy_rt_simple))
)

print(fixef_comparison)
```


```{r}
#| label: Surprisal x previous position entropy blmer models
#| (filter for correct trials + final block and group by matrix_size)
#| 
#| echo: false
#| include: false

m_surprisal_x_entropy_rt_blm <- 
  blmer(log_rt ~ surprisal_c * prev_entropy_c + is_repetition +
         (surprisal_c * prev_entropy_c + is_repetition | subject_id) + (1 | position),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

m_surprisal_x_entropy_acc_blm <-
  bglmer(correct ~ surprisal_c * prev_entropy_c + is_repetition +
         (surprisal_c * prev_entropy_c + is_repetition | subject_id) + (1 | position),
       data=data.m_h1h2,
       family=binomial,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

summary(m_surprisal_x_entropy_rt_blm)
summary(m_surprisal_x_entropy_acc_blm)

confint(m_surprisal_x_entropy_rt_blm, method="Wald") # if CI including 0 usually indicate not significant
```

```{r}
#| label: Surprisal x previous position entropy brm models
#| 
#| echo: false
#| include: false

m_surprisal_x_entropy_rt_brm <- brm(
  log_rt ~ surprisal_c * prev_entropy_c + is_repetition +
    (surprisal_c * prev_entropy_c + is_repetition | subject_id) + (1 | position),
  data = data.m_h1h2)

summary(m_surprisal_x_entropy_rt_brm)
```

### Prune random slopes

base model: `log_rt ~ surprisal_c * prev_entropy_c + is_repetition + (surprisal_c + prev_entropy_c | subject_id) + (1 | position)`

result: we keep random effects: `(surprisal_c + prev_entropy_c | subject_id) + (1 | position)`


```{r}
#| label: Surprisal x previous position entropy lmer models
#| Prune: remove random slopes until AIC smallest
#| 
#| echo: true
#| include: true

m_surprisal_x_entropy_rt_rand_slope_1 <- 
  lmer(log_rt ~ surprisal_c * prev_entropy_c + is_repetition +
         (surprisal_c | subject_id) + (1 | position),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="bobyqa")) # can change

m_surprisal_x_entropy_rt_rand_slope_2 <- 
  lmer(log_rt ~ surprisal_c * prev_entropy_c + is_repetition +
         (prev_entropy_c | subject_id) + (1 | position),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="bobyqa")) # can change

m_surprisal_x_entropy_rt_rand_slope_3 <- 
  lmer(log_rt ~ surprisal_c * prev_entropy_c + is_repetition +
         (surprisal_c + prev_entropy_c || subject_id)+ (1 | position),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="bobyqa")) # can change

m_surprisal_x_entropy_rt_rand_slope_4 <- 
  lmer(log_rt ~ surprisal_c * prev_entropy_c + is_repetition +
         (surprisal_c + prev_entropy_c | subject_id),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="bobyqa")) # can change

AIC(m_surprisal_x_entropy_rt_simple, m_surprisal_x_entropy_rt_rand_slope_1, m_surprisal_x_entropy_rt_rand_slope_2, m_surprisal_x_entropy_rt_rand_slope_3, m_surprisal_x_entropy_rt_rand_slope_4)

# anova(m_surprisal_x_entropy_rt_simple, m_surprisal_x_entropy_rt_rand_slope_2)
# summary(m_surprisal_x_entropy_rt_rand_slope_1)
```

### Prune fixed effects

base model: `log_rt ~ surprisal_c * prev_entropy_c + is_repetition + [random effects left in last section]`

result: we have to keep the base model as the final model

```{r}
#| label: Surprisal x previous position entropy lmer models
#| Prune: remove fixed effects until AIC smallest
#| 
#| echo: true
#| include: true

# base model: m_surprisal_x_entropy_rt_rand_slope_1

m_surprisal_x_entropy_rt_fixed_effects_1 <- 
  lmer(log_rt ~ surprisal_c * prev_entropy_c +
         (surprisal_c + prev_entropy_c | subject_id) + (1 | position),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="bobyqa")) # can change

m_surprisal_x_entropy_rt_fixed_effects_2 <- 
  lmer(log_rt ~ surprisal_c + prev_entropy_c + is_repetition +
         (surprisal_c + prev_entropy_c | subject_id) + (1 | position),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="bobyqa")) # can change

AIC(m_surprisal_x_entropy_rt_simple, m_surprisal_x_entropy_rt_fixed_effects_1, m_surprisal_x_entropy_rt_fixed_effects_2)
```

### previous code

*We then prune the model as follows:*

If the model fails to converge, we will first try blmer/bglmer to see if that addresses convergence.

If not, we will see if any of these random slope structures converges for subject_id (still using blmer/bglmer):

```{r}
#| label: Surprisal x previous position entropy lmer models
#| Prune: position
#| (filter for correct trials + final block and group by matrix_size)
#| 
#| echo: true
#| include: true

m_surprisal_x_entropy_prune_position_rt <- 
  blmer(log_rt ~ surprisal_c * prev_entropy_c + is_repetition +
         (surprisal_c * prev_entropy_c + is_repetition | subject_id),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

m_surprisal_x_entropy_prune_position_acc <-
  bglmer(correct ~ surprisal_c * prev_entropy_c + is_repetition +
         (surprisal_c * prev_entropy_c + is_repetition | subject_id),
       data=data.m_h1h2,
       family=binomial,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

summary(m_surprisal_x_entropy_prune_position_rt)
summary(m_surprisal_x_entropy_prune_position_acc)
```


```{r}
#| label: Surprisal x previous position entropy blmer models
#| Prune: position, repetition
#| (filter for correct trials + final block and group by matrix_size)
#| 
#| echo: true
#| include: true

m_surprisal_x_entropy_prune_position_repetition_rt <- 
  blmer(log_rt ~ surprisal_c * prev_entropy_c +
         (surprisal_c * prev_entropy_c | subject_id),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

m_surprisal_x_entropy_prune_position_repetition_acc <-
  bglmer(correct ~ surprisal_c * prev_entropy_c  +
         (surprisal_c * prev_entropy_c | subject_id),
       data=data.m_h1h2,
       family=binomial,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

summary(m_surprisal_x_entropy_prune_position_repetition_rt)
summary(m_surprisal_x_entropy_prune_position_repetition_acc)
```

And then we will try treating surprisal and previous position entropy as individual fixed effects, instead of interacting:

```{r}
#| label: Surprisal + previous position entropy lmer models
#| (filter for correct trials + final block and group by matrix_size)
#| 
#| echo: true
#| include: true

m_surprisal_entropy_rt <-
  blmer(log_rt ~ surprisal_c + prev_entropy_c + is_repetition +
         (surprisal_c * prev_entropy_c + is_repetition | subject_id) +
         (1 | position),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

m_surprisal_entropy_acc <- 
    bglmer(correct ~ surprisal_c + prev_entropy_c + is_repetition +
           (surprisal_c * prev_entropy_c + is_repetition | subject_id) +
           (1 | position),
       data=data.m_h1h2,
       family=binomial,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

summary(m_surprisal_entropy_rt)
summary(m_surprisal_entropy_acc)
```

```{r}
#| label: Surprisal + previous position entropy effect lmer models
#| Prune: position
#| (filter for correct trials + final block and group by matrix_size)
#| 
#| echo: true
#| include: true

m_surprisal_entropy_prune_position_rt <-
  blmer(log_rt ~ surprisal_c * prev_entropy_c + is_repetition +
         (surprisal_c * prev_entropy_c + is_repetition | subject_id),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

m_surprisal_entropy_prune_position_acc <- 
    bglmer(correct ~ surprisal_c + prev_entropy_c + is_repetition +
         (surprisal_c * prev_entropy_c + is_repetition | subject_id) +
         (1 | position),
       data=data.m_h1h2,
       family=binomial,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

summary(m_surprisal_entropy_prune_position_rt)
summary(m_surprisal_entropy_prune_position_acc)
```

```{r}
#| label: Surprisal + previous position entropy effect lmer models
#| Prune: position, repetition
#| (filter for correct trials + final block and group by matrix_size)
#| 
#| echo: true
#| include: true

m_surprisal_entropy_prune_position_repetition_rt <-
  blmer(log_rt ~ surprisal_c * prev_entropy_c +
         (surprisal_c * prev_entropy_c | subject_id),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

m_surprisal_entropy_prune_position_repetition_acc <- 
    bglmer(correct ~ surprisal_c + prev_entropy_c  +
         (surprisal_c * prev_entropy_c | subject_id) +
         (1 | position),
       data=data.m_h1h2,
       family=binomial,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

summary(m_surprisal_entropy_prune_position_repetition_rt)
summary(m_surprisal_entropy_prune_position_repetition_acc)
```

If that still doesn't work, we can further separate out surprisal_c and prev_entropy_c:

```{r}
#| label: Surprisal effect lmer models
#| (filter for correct trials + final block and group by matrix_size)
#| 
#| echo: true
#| include: true

m_surprisal_rt <-
  blmer(log_rt ~ surprisal_c +
         (surprisal_c | subject_id),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

m_surprisal_acc <- 
    bglmer(correct ~ surprisal_c +
         (surprisal_c | subject_id) +
         (1 | position),
       data=data.m_h1h2,
       family=binomial,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

summary(m_surprisal_rt)
summary(m_surprisal_acc)
```

```{r}
#| label: Previous entropy effect lmer models
#| (filter for correct trials + final block and group by matrix_size)
#| 
#| echo: true
#| include: true

m_entropy_rt <-
  blmer(log_rt ~ prev_entropy_c +
         (prev_entropy_c | subject_id),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

m_prev_entropy_c_acc <- 
    bglmer(correct ~ prev_entropy_c +
         (prev_entropy_c | subject_id) +
         (1 | position),
       data=data.m_h1h2,
       family=binomial,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

summary(m_entropy_rt)
summary(m_entropy_acc)
```

And look at what is_repetition contributes:

```{r}
#| label: Repetition effect lmer models
#| (filter for correct trials + final block and group by matrix_size)
#| 
#| echo: true
#| include: true

m_repetition_rt <-
  blmer(-log_rt ~ is_repetition +
         (is_repetition | subject_id),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

m_repetition_acc <- 
    bglmer(correct ~ is_repetition +
         (is_repetition | subject_id),
       data=data.m_h1h2,
       family=binomial,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

summary(m_repetition_rt)
summary(m_repetition_acc)
```

If none of those converge, we check to see if we made an error somewhere, because at least one of them should converge! The model with the most random slopes that converges is now our base model (for the moment).

Next, we test the significance of random slopes. We iteratively remove random slopes and check whether the result is worse (has a higher AIC). As soon as we can't remove any random slopes without increasing AIC, that is now the random effects structure we will use.

Next, we use model-comparison to determine fixed effects. Our base model is: `~ surprisal_c * prev_entropy_c + is_repetition + [random effects]`

First, we check for a repetition effect by comparing the base model with: `~ surprisal_c * prev_entropy_c + [random effects]`

If the base model has a lower AIC, the effect of repetition is significant. (This is very, very likely). If not, our new base model is the one without the is_repetition effect. We use this base model below.

We test whether there is an interaction by comparing the above with: `~ surprisal_c  + prev_entropy_c + is_repetition + [random effects]`

If the simpler model has a higher AIC, the interaction is significant and we stop. There is a surprisal effect (H1) and an entropy effect (H2).

If there is no interaction, we now compare the no-interaction model to models that lack one of the main effects of entropy or surprisal. So we compare against two models. If AIC for either of the new models is lower, then the corresponding fixed effect is not significant and can be eliminated.

If both entropy and surprisal are significant (eliminating either increases AIC), we are done and interpret H1 and H2. Otherwise, we try eliminating both of these fixed effects. If that increases AIC over a model with one fixed effect, then that fixed effect is definitely significant. (Hopefully this doesn't happen with both fixed effects, which would suggest that surprisal and entropy are so correlated that we can't distinguish them.)

## H3. Moderation from number of positions

filter(correct) %\>% group_by(matrix_size, block) %\>% model()

```{r}
#| label: Num positions effect lmer models
#| (filter for correct trials and group by matrix_size and block)
#| 
#| echo: true
#| include: true

m_matrix_size_rt <-
  blmer(-log_rt ~ matrix_size + is_repetition + (block | subject_id) + (1 | position),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

# m_matrix_size_rt <-
#  lmer(-log_rt ~ matrix_size + is_repetition + (block | subject_id) + (1 | position),
#       data=data.m_h1h2,
#       REML=FALSE,
#       control=lmerControl(optimizer="bobyqa")) # can change

m_matrix_size_acc <- 
    bglmer(correct ~ matrix_size + is_repetition + (block | subject_id) + (1 | position),
       data=data.m_h1h2,
       family=binomial,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

summary(m_matrix_size_rt)
summary(m_matrix_size_acc)
```

For each of the fixed effects used for H1-H2, recover the effect size estimate. Now, for each fixed effect: `effect_size ~ matrix_size*block`

Note that there are no random effects. We use `lm()` and get p-values in the normal way.

Models will be fit with ML for model comparison; final models refit with REML for inference.
