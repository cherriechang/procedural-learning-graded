---
title: "procedural-learning-graded"
author: "Cherrie Chang"
format: html
editor: visual
---

# Data Analysis for Procedural Learning Graded Entropy Design Experiment

## Libraries

```{r}
#| label: Load R libraries
#| echo: false
#| message: false

library(osfr)
library(dplyr)
library(tidyr)
library(tidyverse)
library(zoo)
library(jsonlite)
library(clipr)
```

## Global Variables

```{r}
#| label: Experiment configs that stay constant across participants
#| echo: false
#| include: false

EXPERIMENT_CONFIG <- list(
  datapipe_id_4x4 = "lpRUgvFf5pm4",
  osf_id_4x4 = "5zn6u",
  key_mapping_4pos = c("d","f","j","k"),
  key_mapping_5pos = c("s","d","f","j","k"),
  key_mapping_6pos = c("s","d","f","j","k","l"),
  key_mapping_7pos = c("a","s","d","f","j","k","l"),
  key_mapping_8pos = c("a","s","d","f","j","k","l",";"),
  n_blocks = 20,
  rsi = 120,
  error_feedback_duration = 200,
  error_tone_duration = 100,
  correct_feedback_duration = 200,
  estimated_trial_duration = 500,
  accuracy_threshold = 0.65,
	rt_threshold = 1000
)
```

## Data

### Download Data

```{r}
#| label: Retrieve pilot data from OSF
#| echo: false
#| include: false

osf_retrieve_node("5zn6u") %>%
  osf_ls_files() %>%
  osf_download(path = "data/4x4-data", conflicts="skip")
```

```{r}
#| label: Bind all data together
#| echo: false
#| include: false

df.raw <- list.files("data/4x4-data", full.names = TRUE) %>%
  lapply(read.csv, colClasses="character") %>%
  bind_rows()
```

### Data Cleanup
```{r}
#| label: Filter out unnecessary columns
#| echo: false
#| include: false
df <- subset(df.raw, select=c(trial_index, subject_id, matrix_size, transition_matrix, sequence, conditional_entropies, trials_per_block, total_trials, practice_trials, phase, block, experiment_trial_type, trial_in_block, overall_trial, position, correct_key, response, correct, rt, questionnaire_item)) %>%
  mutate(rt = as.numeric(rt))
```

```{r}
#| label: Clean up data formatting
#| echo: false
#| include: false

# Convert NA values
df <- df %>%
  mutate(across(where(is.character), ~{
    x <- .
    x[x %in% c("NA", "na", "null", "NULL", "")] <- NA
    x
  }))

# Convert boolean values
df <- df %>%
  mutate(across(where(is.character), ~ {
    x <- tolower(.)
    if (all(x %in% c("true", "false", NA))) {
      as.logical(x)
    } else {
      .
    }
  }))

# Convert numeric values
df <- df %>%
  mutate(across(where(is.character), ~ {
    x <- .
    is_num <- suppressWarnings(!is.na(as.numeric(x)) | is.na(x))
    if (all(is_num)) as.numeric(x) else x
  }))

df <- df %>%
  mutate(conditional_entropies = map(conditional_entropies, fromJSON)) %>%
  mutate(transition_matrix = map(transition_matrix, fromJSON))


# Fill down overall_trial, trial_in_block and block
df <- df %>%
 group_by(subject_id) %>%
    arrange(subject_id, row_number()) %>%
    mutate(
      overall_trial = if_else(
        experiment_trial_type %in% c("feedback", "rsi"),
        zoo::na.locf(overall_trial, na.rm = FALSE),  # Fill down
        overall_trial  # Keep as-is
      ),
      trial_in_block = if_else(
        experiment_trial_type %in% c("feedback", "rsi"),
        zoo::na.locf(trial_in_block, na.rm = FALSE), 
        trial_in_block
      ),
      block = if_else(
        experiment_trial_type %in% c("feedback", "rsi"),
        zoo::na.locf(block, na.rm = FALSE), 
        block
      )
    ) %>%
    ungroup()
```


```{r}
#| label: Separate practice, main and questionnaire sections 
#| echo: false
#| include: false

df.practice <- df[df$phase=="practice", ]
df.questionnaire <- df[df$phase=="questionnaire", ]
df <- df[df$phase=="main", ]
```

### Data Exclusions

<!-- TODO: can consider removing subjects that didn't go fullscreen and/or preload failed..? -->
<!-- TODO: used median absolute deviation instead of standard deviation for RT but not sure -->

```{r}
#| label: Exclude subjects that:
#| 1. Made too many mistakes (more than 15%)
#| 2. Have too long response time (look at mean, median and spread):
#| -> exclude if too slow: the subject's median_rt > 1000ms
#| -> or if too noisy: more than 20% of their trials are 3*mad higher than the subjct's median_rt
#| echo: false
#| include: false

accuracy_excluded_subjects <- df %>%
  filter(!is.na(correct)) %>%
  group_by(subject_id) %>%
  summarize(error_rate = mean(!correct)) %>%
  filter(error_rate > 0.10) %>%
  pull(subject_id)

rt_excluded_subjects <- df %>%
  filter(
    (experiment_trial_type == "stimulus" | experiment_trial_type == "retry")
    & !is.na(rt)) %>% 
  group_by(subject_id) %>%
  summarize(
    median_rt = median(rt),
    outlier_prop = mean(rt > median(rt) + 3*mad(rt))
  ) %>%
  filter(median_rt > 1000 | outlier_prop > 0.2) %>%
  pull(subject_id)

df <- df %>%
  filter(!subject_id %in% accuracy_excluded_subjects & !subject_id %in% rt_excluded_subjects)
```

```{r}
#| label: Exclude repetitions and trills from df
#| echo: false
#| include: false

# Sanity check -- are there multiple rows for a given subject-overall_trial combination?
df.duplicate.stimulus.overall_trial <- df %>%
  filter(experiment_trial_type == "stimulus" & !is.na(response)) %>%
  # My silly pre-pilot data had some duplicate rows that had response == null. Might be an earlier
  # version of experiment code as it isn't in the newest dataset
  group_by(subject_id, overall_trial) %>%
  filter(n() > 1) %>%
  arrange(subject_id, overall_trial)
  
# Remove repetitions and trills and print out removal summary
find_and_remove_reps_trills <- function(df) {
  stimulus_only <- df %>%
    filter(experiment_trial_type == "stimulus"& phase == "main" & !is.na(response)) %>%
    group_by(subject_id) %>% 
    arrange(subject_id, overall_trial) %>% 
    mutate(
      prev1_position = lag(position, 1),
      prev2_position = lag(position, 2),
      
      is_repetition = !is.na(prev1_position) & 
                      !is.na(prev2_position) &
                      position == prev1_position & 
                      prev1_position == prev2_position,
      
      is_trill = !is.na(prev1_position) & 
                 !is.na(prev2_position) &
                 position == prev2_position & 
                 position != prev1_position,
      
      has_pattern = is_repetition | is_trill
    ) %>%
    ungroup()
  
  # Create summary per subject
  pattern_summary <- stimulus_only %>%
    group_by(subject_id) %>%
    summarise(
      total_trials = as.numeric(first(total_trials)),  # Get from the column
      n_repetitions = sum(is_repetition, na.rm = TRUE),
      n_trills = sum(is_trill, na.rm = TRUE),
      total_patterns = sum(has_pattern, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    mutate(
      trials_removed = n_repetitions + n_trills,
      trials_remaining = total_trials - trials_removed,
      pct_data_loss = round((trials_removed / total_trials) * 100, 2)
    )
  
  # Print overall summary
  cat("\n=== Pattern Detection & Removal Summary ===\n")
  cat("Total subjects:          ", nrow(pattern_summary), "\n")
  cat("Total main trials:       ", sum(pattern_summary$total_trials), "\n")
  cat("Total repetitions:       ", sum(pattern_summary$n_repetitions), "\n")
  cat("Total trills:            ", sum(pattern_summary$n_trills), "\n")
  cat("Total patterns removed:  ", sum(pattern_summary$trials_removed), "\n")
  cat("Overall data loss:       ", 
      round(sum(pattern_summary$trials_removed) / sum(pattern_summary$total_trials) * 100, 2), 
      "%\n\n")
  
  cat("--- Per Subject ---\n")
  print(pattern_summary)
  cat("\n")
  
  # Get subject-trial combinations that have patterns (to remove)
  pattern_trials <- stimulus_only %>%
    filter(has_pattern) %>%
    select(subject_id, overall_trial)
  
  # Remove all rows that belong to pattern trials
  cleaned_df <- df %>%
    anti_join(pattern_trials, by = c("subject_id", "overall_trial"))
  
  cat("Original df rows:        ", nrow(df), "\n")
  cat("Cleaned df rows:         ", nrow(cleaned_df), "\n")
  cat("Rows removed:            ", nrow(df) - nrow(cleaned_df), "\n\n")
  
  # Return both the cleaned data and the summary
  return(list(
    data = cleaned_df,
    summary = pattern_summary
  ))
}

reps_trills_removal <- find_and_remove_reps_trills(df)
df <- reps_trills_removal$data
removal_summary_per_sub <- reps_trills_removal$summary
```

```{r}
#| label: Filter df down to only stimulus, non-retry trials
#| echo: false
#| include: false

df <- df %>%
  filter(experiment_trial_type=="stimulus" & !is.na(rt))
```

```{r}
#| label: Add entropy for each stimulus trial
#| echo: false
#| include: false

df <- df %>%
  mutate(entropy = map2_dbl(
    conditional_entropies, position,
    ~ {
      # case 1: position is NA → skip = return NA
      if (is.na(.y)) return(NA_real_)
      
      idx <- .y + 1  # convert 0-based to 1-based
      
      # case 2: index out of bounds → return NA
      if (idx > length(.x) || idx < 1) return(NA_real_)
      
      # otherwise extract normally
      .x[idx]
    }
  ))
```

```{r}
#| label: Make a new column for previous position entropy
#| echo: false
#| include: false

df <- df %>%
  group_by(subject_id, block) %>%
  mutate(previous_entropy=lag(entropy, 1))
```

```{r}
#| label: Make a new column for log(rt)
#| echo: false
#| include: false

df <- df %>%
  mutate(log_rt=log(rt))
```

```{r}
#| label: Make a new column for is_repetition
#| echo: false
#| include: false

df <- df %>%
  mutate(is_repetition=(position==lag(position,1)))
```

```{r}
#| label: Remove first trial of each block
#| echo: false
#| include: false

df <- df %>%
  group_by(block) %>%
  slice(2:n())
```
## Stats!

### Power Analysis

```{r}
#| label: Make subset of df with only correct trials
#| echo: false
#| include: false

df.correct <- df %>%
  filter(correct)
```

### Descriptive stats

#### Overall
```{r}
#| label: N, total trials, mean, median overall
#| echo: false
#| include: false

# Within subjects
overall_within_subs_stats <- df %>%
  group_by(subject_id) %>%
  summarise(
    accuracy = mean(correct),
    mean_rt = mean(rt[correct]),
    median_rt = median(rt[correct]),
    sd_rt = sd(rt[correct]),
    n_correct_trials = sum(correct),
    n_trials = n(),
    .groups = "drop"
  )

# Across subjects
overall_across_subs_stats <- within_subs_stats %>%
  summarise(
    N = n(),
    mean_mean_rt = mean(mean_rt),        # Mean of means
    between_subs_sd_rt = sd(mean_rt),    # Between-subject SD
    median_median_rt = median(median_rt),# Median of medians
    mean_accuracy = mean(accuracy),
    sd_accuracy = sd(accuracy)
  )
```

#### By Block
```{r}
#| label: N, total trials, mean, median by block
#| echo: false
#| include: false

by_block_within_subs_stats <- df %>%
  group_by(subject_id, block) %>%
  summarise(
    accuracy = mean(correct),
    mean_rt = mean(rt[correct]),
    median_rt = median(rt[correct]),
    sd_rt = sd(rt[correct]),
    n_correct_trials = sum(correct),
    n_trials = n(),
    .groups = "drop"
  )

by_block_across_subs_stats <- by_block_within_subs_stats %>%
  group_by(block) %>%
  summarize(
    N = n(),
    mean_mean_rt = mean(mean_rt),        
    between_subs_sd_rt = sd(mean_rt),    
    median_median_rt = median(median_rt),
    mean_accuracy = mean(accuracy),
    sd_accuracy = sd(accuracy)
  )
```

#### By Matrix Size
```{r}
#| label: N, total trials, mean, median by matrix size
#| echo: false
#| include: false

by_matrix_size_within_subs_stats <- df %>%
  group_by(subject_id, matrix_size) %>%
  summarise(
    accuracy = mean(correct),
    mean_rt = mean(rt[correct]),
    median_rt = median(rt[correct]),
    sd_rt = sd(rt[correct]),
    n_correct_trials = sum(correct),
    n_trials = n(),
    .groups = "drop"
  )

by_matrix_size_across_subs_stats <- by_matrix_size_within_subs_stats %>%
  group_by(matrix_size) %>%
  summarize(
    N = n(),
    mean_mean_rt = mean(mean_rt),        
    between_subs_sd_rt = sd(mean_rt),    
    median_median_rt = median(median_rt),
    mean_accuracy = mean(accuracy),
    sd_accuracy = sd(accuracy)
  )
```

#### By Entropy Level
```{r}
#| label: N, total trials, mean, median by conditional entropy
#| echo: false
#| include: false

by_entropy_within_subs <- df %>%
  group_by(subject_id, entropy) %>%
  summarise(
    accuracy = mean(correct),
    mean_rt = mean(rt[correct]),
    median_rt = median(rt[correct]),
    sd_rt = sd(rt[correct]),
    n_correct_trials = sum(correct),
    n_trials = n(),
    .groups = "drop"
  ) 
  
by_entropy_across_subs <- df %>%
  group_by(entropy) %>%
  summarise(
    N = n(),
      mean_mean_rt = mean(mean_rt),        
      between_subs_sd_rt = sd(mean_rt),    
      median_median_rt = median(median_rt),
      mean_accuracy = mean(accuracy),
      sd_accuracy = sd(accuracy)
    )
  )
```


## Planned
```{r}
#| 
#| m1 <- lmer(rt ~ factor(position) + block + (block | participant) + (1 | position))
#| m2 <- lmer(rt ~ entropy + block + (entropy + block | participant))
#| m3 <- lmer(rt ~ entropy + factor(position) + block + (entropy + block | participant) + (1 | position))

#| anova(m1, m3)
#| anova(m2, m3)
```


