---
title: "procedural-learning-graded-entropy-data-analysis"
author: "Cherrie Chang"
format: html
editor: visual
---

# Data Analysis for Procedural Learning Graded Entropy Design Experiment

## Libraries

```{r}
#| label: Load R libraries
#| echo: false
#| message: false

library(here)
library(osfr)
library(dplyr)
library(tidyr)
library(tidyverse)
library(zoo)
library(jsonlite)
library(clipr)
library(reticulate)
library(lmerTest) # show p value in lmer
library(blme)
library(purrr)
library(broom.mixed)

np <- import("numpy")
```

## Participants

```{r}
#| label: Demographic data
#| echo: false

df.demographics <- list.files(here("demographic-data/"), pattern = "*.csv", full.names=TRUE) %>%
  lapply(function(f) {
    matrix_size <- gsub('.*_(\\dx\\d)\\.csv', '\\1', basename(f))
    read.csv(f) %>%
      mutate(Matrix.size = matrix_size)
  }) %>%
  bind_rows() %>%
  filter(Status=="APPROVED")

overall_N <- nrow(df.demographics)
overall_mean_age <- mean(as.numeric(df.demographics$Age), na.rm=TRUE)
overall_median_age <- median(as.numeric(df.demographics$Age), na.rm=TRUE)
overall_sd_age <- sd(as.numeric(df.demographics$Age), na.rm=TRUE)
overall_age_range <- range(as.numeric(df.demographics$Age), na.rm=TRUE)

N_nationalities <- length(unique(df.demographics$Nationality))
N_languages <- length(unique(df.demographics$Language))

# Gender distribution
gender_counts <- table(df.demographics$Sex)
n_female <- gender_counts["Female"]
n_male <- gender_counts["Male"]
n_other <- sum(gender_counts[!names(gender_counts) %in% c("Female", "Male")], na.rm=TRUE)

df.demographics.group_summary <- df.demographics %>%
  group_by(Matrix.size) %>%
  summarise(N = n(),
            mean_age = mean(as.numeric(Age), na.rm=TRUE),
            sd_age = sd(as.numeric(Age), na.rm=TRUE),
            min_age = min(as.numeric(Age), na.rm=TRUE),
            max_age = max(as.numeric(Age), na.rm=TRUE))

group_N <- first(df.demographics.group_summary$N)
N_5x5 <- df.demographics.group_summary %>%
  filter(Matrix.size=="5x5") %>%
  pull(N)
```

## Experiment Design

```{r}
#| label: Experiment configs that stay constant across participants
#| echo: false
#| include: false

EXPERIMENT_CONFIG <- list(
  osf_id_4x4 = "Emfhw",
  osf_id_5x5 = "Fraxt",
  osf_id_6x6 = "jx48y",
  osf_id_7x7 = "92jq7",
  osf_id_8x8 = "Tx3h7",
  key_mapping_4pos = c("d","f","j","k"),
  key_mapping_5pos = c("s","d","f","j","k"),
  key_mapping_6pos = c("s","d","f","j","k","l"),
  key_mapping_7pos = c("a","s","d","f","j","k","l"),
  key_mapping_8pos = c("a","s","d","f","j","k","l",";"),
  n_blocks = 20,
  rsi = 120,
  error_feedback_duration = 200,
  error_tone_duration = 100,
  correct_feedback_duration = 200,
  estimated_trial_duration = 500,
  accuracy_threshold = 0.65,
	rt_threshold = 1000
)
```

## Transition Matrices

```{r}
#| label: Original transition matrices
#| echo: false
#| include: false

# Shannon entropy (bits) of a single probability vector (skip zeros)
row_entropy <- function(prob_vec) {
  p <- prob_vec[prob_vec > 0]
  -sum(p * log2(p))
}

# Calculate positional entropy for each row in a transition matrix
positional_entropy <- function(mat) {
  apply(mat, MARGIN=1, row_entropy)
}

transition_matrix_4x4 <- matrix(unlist(np$load(here("assets/transition-matrices/matrix_4x4.npy"))$tolist()), nrow=4, byrow=TRUE)
transition_matrix_5x5 <- matrix(unlist(np$load(here("assets/transition-matrices/matrix_5x5.npy"))$tolist()), nrow=5, byrow=TRUE)
transition_matrix_6x6 <- matrix(unlist(np$load(here("assets/transition-matrices/matrix_6x6.npy"))$tolist()), nrow=6, byrow=TRUE)
transition_matrix_7x7 <- matrix(unlist(np$load(here("assets/transition-matrices/matrix_7x7.npy"))$tolist()), nrow=7, byrow=TRUE)
transition_matrix_8x8 <- matrix(unlist(np$load(here("assets/transition-matrices/matrix_8x8.npy"))$tolist()), nrow=8, byrow=TRUE)
all_original_matrices <- list(
  "4x4" = transition_matrix_4x4,
  "5x5" = transition_matrix_5x5,
  "6x6" = transition_matrix_6x6,
  "7x7" = transition_matrix_7x7,
  "8x8" = transition_matrix_8x8
)

all_positional_entropies <- lapply(all_original_matrices, positional_entropy)
all_positional_entropies_df <- lapply(names(all_positional_entropies), function(size) {
  data.frame(
    Matrix.size = size,
    Position = 1:length(all_positional_entropies[[size]]),
    Entropy = all_positional_entropies[[size]]
  )
}) %>%
  bind_rows()

pos_1_entropy <- all_positional_entropies_df %>%
  group_by(Matrix.size) %>%
  filter(Position==1) %>%
  ungroup() %>%
  summarize(range=range(Entropy), mean=mean(Entropy), sd=sd(Entropy))

pos_n_entropy <- all_positional_entropies_df %>%
  group_by(Matrix.size) %>%
  filter(Position==max(Position)) %>%
  ungroup() %>%
  summarize(range=range(Entropy), mean=mean(Entropy), sd=sd(Entropy))

entropy_gradient_summary <- all_positional_entropies_df %>%
  group_by(Matrix.size) %>%
  summarize(entropy_diffs = list(diff(Entropy))) %>%
  ungroup() %>%
  summarize(
    range_diff = list(range(unlist(entropy_diffs))),
    mean_diff = mean(unlist(entropy_diffs)),
    sd_diff = sd(unlist(entropy_diffs))
  )
```

# Statistical Analysis

```{r}
#| label: Retrieve data from OSF
#| echo: false
#| include: false
#| eval: false

# NOTE: Set eval=true only when you need to download data from OSF for the first time.
# Once data is downloaded locally, keep eval=false to speed up rendering.

files_4x4 <- osf_retrieve_node(EXPERIMENT_CONFIG$osf_id_4x4) %>%
  osf_ls_files(n_max = Inf) %>%
  osf_download(path = here("data/4x4-data"), conflicts="skip")

files_5x5 <- osf_retrieve_node(EXPERIMENT_CONFIG$osf_id_5x5) %>%
  osf_ls_files(n_max = Inf) %>%
  osf_download(path = here("data/5x5-data"), conflicts="skip")

files_6x6 <- osf_retrieve_node(EXPERIMENT_CONFIG$osf_id_6x6) %>%
  osf_ls_files(n_max = Inf) %>%
  osf_download(path = here("data/6x6-data"), conflicts="skip")

files_7x7 <- osf_retrieve_node(EXPERIMENT_CONFIG$osf_id_7x7) %>%
  osf_ls_files(n_max = Inf) %>%
  osf_download(path = here("data/7x7-data"), conflicts="skip")

files_8x8 <- osf_retrieve_node(EXPERIMENT_CONFIG$osf_id_8x8) %>%
  osf_ls_files(n_max = Inf) %>%
  osf_download(path = here("data/8x8-data"), conflicts="skip")
```

```{r}
#| label: List local data files
#| echo: false
#| include: false

# But there is some bug in osfr that causes one file name to be duplicated and one file name to be skipped, so alternatively just download manually from OSF and put in data/ folder:
files_4x4 <- list.files("data/4x4-data")
files_5x5 <- list.files("data/5x5-data")
files_6x6 <- list.files("data/6x6-data")
files_7x7 <- list.files("data/7x7-data")
files_8x8 <- list.files("data/8x8-data")
```

```{r}
#| label: Bind all data together
#| echo: false
#| include: false

# Cache df.raw to speed up rendering
df_raw_cache <- here("data/processed/df_raw.rds")

if (file.exists(df_raw_cache)) {
  df.raw <- readRDS(df_raw_cache)
} else {
  df.raw <- list.files(here("data/"), pattern = "*.csv", full.names=TRUE, recursive=TRUE) %>%
    .[!grepl("pilot-data", .)] %>%
    lapply(read.csv) %>%
    bind_rows()

  # Create processed directory if it doesn't exist
  dir.create(here("data/processed"), showWarnings = FALSE, recursive = TRUE)
  saveRDS(df.raw, df_raw_cache)
}
```

```{r}
#| label: Filter out unnecessary columns
#| echo: false
#| include: false

df <- subset(df.raw, select=c(trial_index, subject_id, matrix_size, trials_per_block, total_trials, practice_trials, transition_matrix, conditional_entropies, phase, block, experiment_trial_type, trial_in_block, overall_trial, position, correct_key, response, correct, rt, conditional_entropy, surprisal, questionnaire_item))
```

```{r}
#| label: Clean up data formatting
#| echo: false
#| include: false

# Convert NA values
df <- df %>%
  mutate(across(where(is.character), ~{
    x <- .
    x[x %in% c("NA", "na", "null", "NULL", "")] <- NA
    x
  }))

# Convert boolean values
df <- df %>%
  mutate(across(where(is.character), ~ {
    x <- tolower(.)
    if (all(x %in% c("true", "false", NA))) {
      as.logical(x)
    } else {
      .
    }
  }))

# Convert numeric values
df <- df %>%
  mutate(across(where(is.character), ~ {
    x <- .
    is_num <- suppressWarnings(!is.na(as.numeric(x)) | is.na(x))
    if (all(is_num)) as.numeric(x) else x
  }))
```

```{r}
#| label: Fill down overall_trial, trial_in_block, block
#| echo: false
#| include: false

df <- df %>%
    group_by(subject_id) %>%
    arrange(subject_id, row_number()) %>%
    mutate(
      overall_trial = if_else(
        experiment_trial_type %in% c("feedback", "rsi"),
        zoo::na.locf(overall_trial, na.rm = FALSE),  # Fill down
        overall_trial  # Keep as-is
      ),
      trial_in_block = if_else(
        experiment_trial_type %in% c("feedback", "rsi"),
        zoo::na.locf(trial_in_block, na.rm = FALSE), 
        trial_in_block
      ),
      block = if_else(
        experiment_trial_type %in% c("feedback", "rsi"),
        zoo::na.locf(block, na.rm = FALSE), 
        block
      )
    ) %>%
    ungroup()
```

```{r}
#| label: Sanity check for unique subject_ids, matrix size, total number of trials, practice trials, transition matrices, conditional entropies and sequences across subjects and conditions
#| echo: false
#| include: false

unique_subjects <- unique(df$subject_id)

# Per-subject constants grouped by matrix_size
df %>%
  distinct(matrix_size, subject_id, total_trials, practice_trials, transition_matrix, conditional_entropies) %>%
  group_by(matrix_size) %>%
  summarize(
    n_subjects = n_distinct(subject_id),
    total_trials = unique(total_trials),
    practice_trials = unique(practice_trials),
    transition_matrix = list(unique(transition_matrix)),
    conditional_entropies = list(unique(conditional_entropies))
  )

# Unique position sequences per matrix_size
df %>%
  group_by(matrix_size, subject_id) %>%
  summarize(
    sequence = paste(position, collapse = ","),
    .groups = "drop"
  ) %>%
  group_by(matrix_size) %>%
  summarize(
    n_subjects = n_distinct(subject_id),
    n_unique_sequences = n_distinct(sequence)
  )

df <- df[, !(names(df) %in% c("transition_matrix", "conditional_entropies"))]

# Shows only 1 unique transition matrix and conditional entropies for conditions 6x6, 7x7 and 8x8 because of an error in data collection for those conditions after removing row by row log of the transition matrix and conditional entropies from the data files to save space. However, the code to shuffle those matrices and corresponding conditional entropies are still the same, so we believe participants are still each seeing a shuffled matrix and a different sequence in these conditions.
```

```{r}
#| label: Separate practice, main and questionnaire sections
#| echo: false
#| include: false

df.practice <- df[df$phase=="practice", ]
df.questionnaire <- df[df$phase=="questionnaire", ]
df <- df[df$phase=="main", ]
```

```{r}
#| label: exclude-subjects
#| echo: false
#| include: false

# Exclude subjects that
# 1. Made too many mistakes (more than 15%)
# 2. Have too long response time (look at mean, median and spread)
# -> exclude if too slow--the subject's median_rt > 1000ms
# -> or if too noisy--more than 20% of their trials are 3*mad higher than the subject's median_rt

accuracy_excluded_subjects <- df %>%
  filter(matrix_size==8) %>%
  filter(!is.na(correct)) %>%
  group_by(subject_id) %>%
  summarize(error_rate = mean(!correct)) %>%
  filter(error_rate > 0.10) %>%
  pull(subject_id)

rt_excluded_subjects <- df %>%
  filter(
    (experiment_trial_type == "stimulus" | experiment_trial_type == "retry")
    & !is.na(rt)) %>% 
  group_by(subject_id) %>%
  summarize(
    median_rt = median(rt),
    outlier_prop = mean(rt > median(rt) + 3*mad(rt))
  ) %>%
  filter(median_rt > 1000 | outlier_prop > 0.2) %>%
  pull(subject_id)

df <- df %>%
  filter(!subject_id %in% accuracy_excluded_subjects & !subject_id %in% rt_excluded_subjects)
```

```{r}
#| label: Filter df down to only stimulus, non-retry trials
#| echo: false
#| include: false

df <- df %>%
  filter(experiment_trial_type=="stimulus" & !is.na(rt))
```

```{r}
#| label: Remove first trial of each block
#| echo: false
#| include: false

df <- df %>%
  group_by(block, subject_id) %>%
  slice(2:n())
```

```{r}
#| label: Make a new column for log(rt), previous position entropy, prev_entropy_c, surprisal_c, is_repetition
#| echo: false
#| include: false

# Cache fully processed df
df_processed_cache <- here("data/processed/df_processed.rds")

if (file.exists(df_processed_cache)) {
  df <- readRDS(df_processed_cache)
} else {
  df <- df %>%
    mutate(log_rt=log(rt)) %>%
    filter(!is.infinite(log_rt)) %>%
    mutate(is_repetition=(position==lag(position,1))) %>%
    group_by(subject_id, block) %>%
    mutate(previous_entropy=lag(conditional_entropy, 1)) %>%
    ungroup() %>%
    group_by(matrix_size) %>%
    mutate(prev_entropy_c=previous_entropy-mean(previous_entropy, na.rm=TRUE)) %>%
    mutate(surprisal_c=surprisal-mean(surprisal, na.rm=TRUE)) %>%
    ungroup()

  saveRDS(df, df_processed_cache)
}
```

```{r}
#| label: Make subset of df with only correct trials
#| echo: false
#| include: false

# Cache correct trials df
df_correct_cache <- here("data/processed/df_correct.rds")

if (file.exists(df_correct_cache)) {
  df.correct <- readRDS(df_correct_cache)
} else {
  df.correct <- df %>%
    filter(correct)

  saveRDS(df.correct, df_correct_cache)
}
```

# Model - H0

```{r}
#| label: Prepare data for H0 models
#| echo: false
#| eval: false

df.m_h0 <- df
df.m_h0.correct <- df.correct
```

```{r}
#| label: H0 Learning effect lmer models
#| (filter for correct trials and group by matrix_size)
#| echo: false

m_h0_rt <-
  lmer(log_rt ~ block * is_repetition + (block * is_repetition| subject_id) + (1 | position),
  data=df.m_h0.correct,
  REML=FALSE,
  control=lmerControl(optimizer="bobyqa")) # can change

summary(m_h0_rt)

df.m_h0.correct <- df.correct %>%
  group_by(matrix_size)
  
m_h0_acc <-
  glmer(correct ~ block + is_repetition + (block | subject_id) + (1 | position),
  data=df.m_h0,
  family=binomial,
 control=glmerControl(optimizer="bobyqa")) # can change

summary(m_h0_acc)
```

## H1 & H2. Surprisal and previous position entropy effects

For H1 & H2, we analyze each block independently. First, we determine the effects structure by analyzing only the final block as follows: *(When the best-fit base model for surprisal and/or previous position entropy effects has been found, we can then examine learning trajectories by adding block as a continuous predictor)*

```{r}
#| label: H1H2 Effect lmer models
#| (filter for last block only, for each matrix_size)
#| echo: false

df.m_h1h2.finalblock <- df %>%
  filter(block==EXPERIMENT_CONFIG[["n_blocks"]]-1)

data_list <- split(df.m_h1h2.finalblock, df.m_h1h2.finalblock$matrix_size)

models <- map(data_list, ~ lmer(
  log_rt ~ surprisal_c * prev_entropy_c + is_repetition +
    (surprisal_c * prev_entropy_c || subject_id) + (1 | position),
  data = .x, 
  REML=FALSE,
  control=lmerControl(optimizer="bobyqa")))

model_summaries <- map(models, summary)
model_summaries[2]
```

### per condition models for final block

#### Prune random slopes

base model: log_rt \~ surprisal_c \* prev_entropy_c + is_repetition + (surprisal_c \* prev_entropy_c \|\| subject_id) + (1 \| position)

result: keep base model

```{r}
model_structures_random_slope <- list(
  base = "(surprisal_c * prev_entropy_c || subject_id) + (1 | position)",
  main = "(surprisal_c + prev_entropy_c || subject_id) + (1 | position)",
  s_only = "(surprisal_c | subject_id) + (1 | position)",
  e_only = "(prev_entropy_c | subject_id) + (1 | position)",
  intercept = "(1 | subject_id) + (1 | position)"
)

all_models_random_slope <- map(
  model_structures_random_slope,
  ~ map(data_list, function(dat) {
    lmer(
      as.formula(
        paste0("log_rt ~ surprisal_c * prev_entropy_c + is_repetition + ", .x)
      ),
      data = dat,
      REML = FALSE,
      control = lmerControl(optimizer = "bobyqa")
    )
  })
)

aic_table_random_slope <- map_dfr(
  names(all_models_random_slope),
  function(model_name) {
    map_dfr(
      names(all_models_random_slope[[model_name]]),
      function(cond) {
        m <- all_models_random_slope[[model_name]][[cond]]
        data.frame(
          model = model_name,
          matrix_size = cond,
          AIC = AIC(m),
          isSingular = isSingular(m)
        )
      }
    )
  }
)

aic_table_random_slope %>% 
  filter(aic_table_random_slope$isSingular == FALSE) %>% 
  group_by(model) %>%
  summarise(total_AIC = sum(AIC)) %>%
  arrange(total_AIC)
  #group_by(matrix_size) %>% 
  #arrange(matrix_size, AIC)
```

#### Prune fixed effects:

base model: log_rt \~ surprisal_c \* prev_entropy_c + is_repetition + (surprisal_c \* prev_entropy_c \|\| subject_id) + (1 \| position)

results: keep base model

```{r}
model_structures_fixed_effect <- list(
  base = "surprisal_c * prev_entropy_c + is_repetition",
  no_interaction = "surprisal_c + prev_entropy_c + is_repetition",
  no_is_repetition = "surprisal_c * prev_entropy_c",
  only_main = "surprisal_c + prev_entropy_c",
  surprisal_is_repetition = "surprisal_c + is_repetition",
  entropy_is_repetition = "prev_entropy_c + is_repetition"
)

all_models_fixed_effect <- map(
  model_structures_fixed_effect,
  ~ map(data_list, function(dat) {
    lmer(
      as.formula(
        paste0("log_rt ~ ", .x, " + (surprisal_c * prev_entropy_c || subject_id) + (1 | position)")
      ),
      data = dat,
      REML = FALSE,
      control = lmerControl(optimizer = "bobyqa")
    )
  })
)

aic_table_fixed_effect <- map_dfr(
  names(all_models_fixed_effect),
  function(model_name) {
    map_dfr(
      names(all_models_fixed_effect[[model_name]]),
      function(cond) {
        m <- all_models_fixed_effect[[model_name]][[cond]]
        data.frame(
          model = model_name,
          matrix_size = cond,
          AIC = AIC(m),
          isSingular = isSingular(m)
        )
      }
    )
  }
)

aic_table_fixed_effect %>% 
  filter(aic_table_fixed_effect$isSingular == FALSE) %>% 
  group_by(model) %>%
  summarise(total_AIC = sum(AIC)) %>%
  arrange(total_AIC)
  #group_by(matrix_size) %>% 
  #arrange(matrix_size, AIC)
```

#### plotting final models per condition (final blocks): fixed effects (exclude intercepts)

```{r}
theme_set(theme_minimal())

effects_df <- map_dfr(
  names(models),
  ~ broom.mixed::tidy(models[[.x]]) %>%
    filter(effect == "fixed" & term != "(Intercept)") %>%
    mutate(matrix_size = .x)
) %>%
  mutate(
    sig_label = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01 ~ "**",
      p.value < 0.05 ~ "*",
      TRUE ~ ""
    )
  )

#effects_df$matrix_size <- as.numeric(effects_df$matrix_size)

ggplot(effects_df, aes(x = matrix_size, y = estimate, color = term, group = term)) +
  geom_line() +
  geom_point() +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
  geom_text(aes(label = sig_label), vjust = -1.2, size = 5, show.legend = FALSE)
  labs(x = "Matrix Size", y = "Effect Estimate", color = "Parameter") + 
  theme_minimal()
```

### learning across blocks

#### try add block as a variable in the model

```{r}

_all_blocks <- df %>% filter(!is.infinite(log_rt))

data_list_all_blocks <- split(
    _all_blocks, data.m_h1h2_all_blocks$matrix_size)

models_all <- map(data_list_all_blocks, ~ lmer(
  log_rt ~ surprisal_c * prev_entropy_c * block + block * is_repetition +
    (surprisal_c + prev_entropy_c + is_repetition + block | subject_id) + (1 | position),
  data = .x, 
  REML=FALSE,
  control=lmerControl(optimizer="bobyqa")))

#iwalk(models_all, function(model, name) {
#  saveRDS(model, paste0("./models/all_block_per_condition/all_block_models_", name, ".rds"))
#})

# to read
#model_names <- c("4", "5", "6", "7", "8")
#models_all <- map(model_names, ~ readRDS(paste0("./models/all_block_per_condition/all_block_models_", .x, ".rds")))
#names(models_all) <- model_names

model_summaries_all_blocks <- map(models_all, summary)
model_summaries_all_blocks[5]
```

#### try seperate models per block

all models no singular fit: log_rt \~ surprisal_c \* prev_entropy_c + is_repetition + (prev_entropy_c \| subject_id) + (1 \| position)

```{r}
cur_condition <- 8
data_m4 <- subset(df, matrix_size == cur_condition & !is.infinite(log_rt)) # can change

data_list_block <- split(data_m4, data_m4$block)

# random effects: (prev_entropy_c | subject_id) + (1 | position) no singular fit for all conditions
models_block <- map2(names(data_list_block),
                     data_list_block,
                     function(name, dat) {
                       model_path <- paste0("./models/per_block_condition_", cur_condition, "/model_block_", name, ".rds") 
                       dir_path <- dirname(model_path)
                       if (!dir.exists(dir_path)) dir.create(dir_path, recursive = TRUE)
                       if (file.exists(model_path)) {
                         readRDS(model_path)
                       } else {
                         m <- lmer(
                           log_rt ~ surprisal_c * prev_entropy_c + is_repetition + 
                             (prev_entropy_c | subject_id) + (1 | position),
                           data = dat, 
                           REML = FALSE,
                           control = lmerControl(optimizer = "bobyqa")
                         )
                         saveRDS(m, model_path)
                         m
                       }
                     }
)
  
model_summaries_block <- map(models_block, summary)
model_summaries_block[10]
```

#### ploting final models per condition (per blocks): fixed effects (exclude intercepts)

```{r}
effects_block <- map_dfr(
  names(models_block),
  ~ broom.mixed::tidy(models_block[[.x]]) %>%
    filter(effect == "fixed" & term != "(Intercept)") %>%
    mutate(block = as.numeric(.x))
) %>%
  mutate(
    sig_label = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01 ~ "**",
      p.value < 0.05 ~ "*",
      TRUE ~ ""
    )
  )

ggplot(effects_block, aes(x = block, y = estimate, color = term, group = term)) +
  geom_line() +
  geom_point() +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
  geom_text(aes(label = sig_label), vjust = -1.2, size = 5, show.legend = FALSE) +
  labs(x = "Block", y = "Effect Estimate", color = "Parameter") +
  theme_minimal()
```

## H3. Moderation from number of positions

filter(correct) %\>% group_by(matrix_size, block) %\>% model()

```{r}
#| label: Num positions effect lmer models
#| (filter for correct trials and group by matrix_size and block)
#| 
#| echo: true
#| include: true

m_matrix_size_rt <-
  blmer(-log_rt ~ matrix_size + is_repetition + (block | subject_id) + (1 | position),
       data=data.m_h1h2,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

# m_matrix_size_rt <-
#  lmer(-log_rt ~ matrix_size + is_repetition + (block | subject_id) + (1 | position),
#       data=data.m_h1h2,
#       REML=FALSE,
#       control=lmerControl(optimizer="bobyqa")) # can change

m_matrix_size_acc <- 
    bglmer(correct ~ matrix_size + is_repetition + (block | subject_id) + (1 | position),
       data=data.m_h1h2,
       family=binomial,
       REML=FALSE,
       control=lmerControl(optimizer="nloptwrap")) # can change

summary(m_matrix_size_rt)
summary(m_matrix_size_acc)
```

For each of the fixed effects used for H1-H2, recover the effect size estimate. Now, for each fixed effect: `effect_size ~ matrix_size*block`

Note that there are no random effects. We use `lm()` and get p-values in the normal way.

Models will be fit with ML for model comparison; final models refit with REML for inference.

```{r}
#| label: Extract coefficients from per-block models
#| echo: true
#| include: true

# Extract coefficients from all per-block models across all conditions
# This creates a dataframe with: matrix_size, block, and coefficient estimates

library(broom.mixed)

# Get all per-block model directories
condition_dirs <- list.files("models/", pattern = "per_block_condition_", full.names = TRUE)

# Extract coefficients from each condition's per-block models
coef_df <- map_dfr(condition_dirs, function(dir) {
  condition_num <- gsub(".*per_block_condition_(\\d+)", "\\1", dir)
  matrix_size <- paste0(condition_num, "x", condition_num)

  # Get all model files in this directory
  model_files <- list.files(dir, pattern = "model_block_.*\\.rds", full.names = TRUE)

  # Extract block number and coefficients from each model
  map_dfr(model_files, function(file) {
    block_num <- as.numeric(gsub(".*model_block_(\\d+)\\.rds", "\\1", file))

    # Load model and extract fixed effects
    m <- readRDS(file)
    coefs <- fixef(m)

    # Return as a row
    data.frame(
      matrix_size = matrix_size,
      matrix_size_num = as.numeric(condition_num),
      block = block_num,
      intercept = coefs["(Intercept)"],
      surprisal = coefs["surprisal_c"],
      prev_entropy = coefs["prev_entropy_c"],
      interaction = coefs["surprisal_c:prev_entropy_c"],
      is_repetition = coefs["is_repetitionTRUE"]
    )
  })
})

# Center block and matrix_size as recommended by Josh
# Block: blocks 0-19 centered to (-9.5, -8.5, ..., 8.5, 9.5)
# Matrix_size: sizes 4-8 centered to (-2, -1, 0, 1, 2)
coef_df <- coef_df %>%
  mutate(
    block_c = block - 9.5,  # center at midpoint between 0-19
    matrix_size_c = matrix_size_num - 6  # center at 6 (middle of 4-8)
  )

# View structure
head(coef_df)
summary(coef_df)
```

```{r}
#| label: H3 models - matrix size moderation
#| echo: true
#| include: true

# H3: Test whether surprisal, entropy, and interaction effects
# are moderated by matrix_size and block

# Model 1: Surprisal effect ~ matrix_size * block
m_h3_surprisal <- lm(surprisal ~ matrix_size_num * block, data = coef_df)
summary(m_h3_surprisal)

# Model 2: Previous entropy effect ~ matrix_size * block
m_h3_entropy <- lm(prev_entropy ~ matrix_size_num * block, data = coef_df)
summary(m_h3_entropy)

# Model 3: Interaction effect ~ matrix_size * block
m_h3_interaction <- lm(interaction ~ matrix_size_num * block, data = coef_df)
summary(m_h3_interaction)

# Model 4: Repetition effect ~ matrix_size * block
m_h3_repetition <- lm(is_repetition ~ matrix_size_num * block, data = coef_df)
summary(m_h3_repetition)
```

```{r}
#| label: H3 visualization
#| echo: false
#| include: true

# Create plots directory if it doesn't exist
dir.create("plots", showWarnings = FALSE)

# Visualize how effects change across matrix size and block

# Plot surprisal effect
p1 <- ggplot(coef_df, aes(x = block, y = surprisal, color = matrix_size, group = matrix_size)) +
  geom_smooth(method = "lm", se = TRUE, alpha = 0.2) +
  geom_point(alpha = 0.3) +
  labs(title = "H1: Surprisal Effect Across Learning",
       x = "Block", y = "Surprisal Coefficient", color = "Matrix Size") +
  theme_minimal()
ggsave("plots/h3_surprisal_by_block.png", p1, width = 8, height = 6, dpi = 300)
print(p1)

# Plot entropy effect
p2 <- ggplot(coef_df, aes(x = block, y = prev_entropy, color = matrix_size, group = matrix_size)) +
  geom_smooth(method = "lm", se = TRUE, alpha = 0.2) +
  geom_point(alpha = 0.3) +
  labs(title = "H2: Entropy Effect Across Learning",
       x = "Block", y = "Previous Entropy Coefficient", color = "Matrix Size") +
  theme_minimal()
ggsave("plots/h3_entropy_by_block.png", p2, width = 8, height = 6, dpi = 300)
print(p2)

# Plot interaction effect
p3 <- ggplot(coef_df, aes(x = block, y = interaction, color = matrix_size, group = matrix_size)) +
  geom_smooth(method = "lm", se = TRUE, alpha = 0.2) +
  geom_point(alpha = 0.3) +
  labs(title = "H2: Surprisal Ã— Entropy Interaction Across Learning",
       x = "Block", y = "Interaction Coefficient", color = "Matrix Size") +
  theme_minimal()
ggsave("plots/h3_interaction_by_block.png", p3, width = 8, height = 6, dpi = 300)
print(p3)

# Plot matrix size effect (averaging across blocks)
coef_summary <- coef_df %>%
  group_by(matrix_size, matrix_size_num) %>%
  summarize(
    surprisal_mean = mean(surprisal, na.rm = TRUE),
    surprisal_se = sd(surprisal, na.rm = TRUE) / sqrt(n()),
    entropy_mean = mean(prev_entropy, na.rm = TRUE),
    entropy_se = sd(prev_entropy, na.rm = TRUE) / sqrt(n()),
    interaction_mean = mean(interaction, na.rm = TRUE),
    interaction_se = sd(interaction, na.rm = TRUE) / sqrt(n())
  )

p4 <- ggplot(coef_summary, aes(x = matrix_size_num)) +
  geom_line(aes(y = surprisal_mean, color = "Surprisal")) +
  geom_point(aes(y = surprisal_mean, color = "Surprisal")) +
  geom_errorbar(aes(ymin = surprisal_mean - surprisal_se,
                    ymax = surprisal_mean + surprisal_se, color = "Surprisal"),
                width = 0.2) +
  geom_line(aes(y = entropy_mean, color = "Entropy")) +
  geom_point(aes(y = entropy_mean, color = "Entropy")) +
  geom_errorbar(aes(ymin = entropy_mean - entropy_se,
                    ymax = entropy_mean + entropy_se, color = "Entropy"),
                width = 0.2) +
  labs(title = "H3: Effect Size by Matrix Size (Averaged Across Blocks)",
       x = "Matrix Size", y = "Coefficient Estimate", color = "Effect") +
  theme_minimal()
ggsave("plots/h3_effects_by_matrix_size.png", p4, width = 8, height = 6, dpi = 300)
print(p4)
```